dataset_parameters:
  storage_mode: 'memory'                                     # 'memory' or 'disk'. Where to load the dataset
  root_dir: 'data/datasets'                                  # Path to root directory for the dataset files
  nodes_shp_file: 'Geometry/cell_centers_with_ele.shp'       # Filename of shapefile containing node information
  edges_shp_file: 'Geometry/links_with_slope.shp'            # Filename of shapefile containing edge information
  dem_file: 'Geometry/DEM.tif'                               # Filename of DEM file
  features_stats_file: 'features_stats.yaml'                 # Filename for the yaml file containing feature statistics (mean, std, min, max). Generated when initializing the dataset

  previous_timesteps: 1                                      # Number of previous timesteps to consider for input features
  normalize: True                                            # Whether to normalize features
  timestep_interval: 900                                     # Interval between timesteps in seconds
  spin_up_time: 259200                                       # Spin up time in seconds. Used to trim the beginning of the flood event. Can be defined per Run ID
  # spin_up_time:
  #   38: 259200
  #   39: 259200
  #   40: 259200
  #   41: 259200
  #   default: 129600
  time_from_peak: null                                       # Time after peak flow to consider in data in seconds. Used to trim the end of the flood event. Set to null to include the entire event
  inflow_boundary_nodes:                                     # List of inflow boundary node IDs for boundary conditions
  - 1248
  outflow_boundary_nodes:                                    # List of outflow boundary node IDs for boundary conditions
  - 1253
  - 1129

  training:
    dataset_summary_file: 'train.csv'                        # Filename of csv file containing the list of training flood events (Run IDs and HEC-RAS file paths)
    event_stats_file: 'train_event_stats.yaml'               # Filename for the yaml file containing training event statistics. Generated when initializing the dataset

  testing:
    dataset_summary_file: 'test.csv'                         # Filename of csv file containing the list of testing flood events (Run IDs and HEC-RAS file paths)
    event_stats_file: 'test_event_stats.yaml'                # Filename for the yaml file containing testing event statistics. Generated when initializing the dataset

training_parameters:
  log_path             : 'logs/loss_calibration.log'         # Path to save training logs
  model_dir            : 'saved_models'                      # Path to directory to save trained models
  stats_dir            : 'training_stats'                    # Path to directory to save training statistics
  checkpoint_path      : null                                # Path to load a pre-trained model; If set to null, no pre-trained model is loaded
  num_epochs           : 10                                  # Number of epochs
  num_epochs_dyn_loss  : 10                                  # Number of epochs to determine loss scaling ratios dynamically. Usually 10 epochs is sufficient
  batch_size           : 32                                  # Batch size
  learning_rate        : 0.0001                              # Learning rate
  adam_weight_decay    : 0                                   # Weight decay
  gradient_clip_value : 0.5                                  # Gradient clipping value. If set to null, no gradient clipping is applied
  early_stopping_patience: 15                                # Early stopping patience in number of epochs. If set to null, no early stopping is applied
  val_split_percent  : 0.1                                   # Percentage of validation split for autoregressive training

  autoregressive:
    enabled            : False                               # Enable autoregressive training
    init_num_timesteps : 1                                   # Initial number of timesteps for autoregressive training
    total_num_timesteps: 1                                   # Total number of timesteps for autoregressive training
    timestep_increment : 1                                   # Number of timesteps to increase after each curriculum step
    max_curriculum_epochs: 100                               # Maximum number of curriculum steps
    learning_rate_decay  : 0.7                               # Learning rate decay factor after each curriculum step

loss_func_parameters:
  node_loss: 'mse'                                           # Loss function for node features. Options: 'mse', 'mae', 'huber'
  edge_loss: 'mse'                                           # Loss function for edge features. Options: 'mse', 'mae', 'huber'
  node_loss_weight: 1.0                                      # Importance weight for node prediction loss. Applied after scaling.
  edge_pred_loss_scale: 1.0                                  # Value used to scale edge prediction loss. This is used as an initial value when using dynamic loss scaling
  edge_loss_weight: 0.4                                      # Importance weight for edge prediction loss. Applied after scaling.
  use_global_mass_loss: True                                 # Enable global mass conservation in loss function
  global_mass_loss_scale: 1.0                                # Value used to scale global mass conservation loss. This is used as an initial value when using dynamic loss scaling
  global_mass_loss_weight: 0.01                              # Importance weight for global mass conservation loss. Applied after scaling.
  use_local_mass_loss: True                                  # Enable local mass conservation in loss function
  local_mass_loss_scale: 1.0                                 # Value used to scale local mass conservation loss. This is used as an initial value when using dynamic loss scaling
  local_mass_loss_weight: 0.01                               # Importance weight for local mass conservation loss. Applied after scaling.

  huber:
    delta: 0.15                                               # Delta parameter for Huber loss function.

testing_parameters:
  log_path: null                                             # Path to save testing logs
  output_dir: 'saved_metrics'                                # Directory to save testing results
  rollout_start: 0                                           # Start timestep for the test rollout
  rollout_timesteps: null                                    # Number of timesteps for the test rollout. Set to null to roll out until the end of the event

model_parameters:                                            # Model-specific parameters
  GCN:
    hidden_features: 64
    num_layers: 3
    activation: 'relu'
    residual: False
    encoder_layers: 0
    encoder_activation: 'relu'
    decoder_layers: 0
    decoder_activation: 'relu'

  EdgeGCN:
    hidden_features: 64
    num_layers: 3
    activation: 'relu'
    residual: False
    encoder_layers: 0
    encoder_activation: 'relu'
    decoder_layers: 3
    decoder_activation: 'relu'

  GAT:
    hidden_features: 64
    use_edge_features: False
    num_layers: 3
    activation: 'relu'
    residual: False
    num_heads: 1
    dropout: 0.0
    add_self_loops: True
    negative_slope: 0.2
    attn_bias: True
    attn_residual: True
    encoder_layers: 0
    encoder_activation: 'relu'
    decoder_layers: 0
    decoder_activation: 'relu'

  EdgeGAT:
    hidden_features: 64
    use_edge_features: True
    num_layers: 3
    activation: 'relu'
    residual: False
    num_heads: 1
    dropout: 0.0
    add_self_loops: True
    negative_slope: 0.2
    attn_bias: True
    attn_residual: True
    encoder_layers: 0
    encoder_activation: 'relu'
    decoder_layers: 3
    decoder_activation: 'relu'

  GIN:
    hidden_features: 64
    num_layers: 3
    activation: 'relu'
    mlp_layers: 3
    eps: 0.0
    train_eps: False
    encoder_layers: 0
    encoder_activation: 'relu'
    decoder_layers: 0
    decoder_activation: 'relu'

  EdgeGIN:
    hidden_features: 64
    num_layers: 3
    activation: 'relu'
    mlp_layers: 3
    eps: 0.0
    train_eps: False
    encoder_layers: 0
    encoder_activation: 'relu'
    decoder_layers: 3
    decoder_activation: 'relu'

  GINE:
    hidden_features: 64
    num_layers: 3
    activation: 'relu'
    mlp_layers: 3
    eps: 0.0
    train_eps: False
    encoder_layers: 0
    encoder_activation: 'relu'
    decoder_layers: 0
    decoder_activation: 'relu'

  EdgeGINE:
    hidden_features: 64
    num_layers: 3
    activation: 'relu'
    mlp_layers: 3
    eps: 0.0
    train_eps: False
    encoder_layers: 0
    encoder_activation: 'relu'
    decoder_layers: 3
    decoder_activation: 'relu'

  GraphSAGE:
    hidden_features: 64
    num_layers: 3
    activation: 'relu'
    aggr: 'mean'
    normalize: False
    root_weight: True
    project: False
    bias: True
    encoder_layers: 0
    encoder_activation: 'relu'
    decoder_layers: 0
    decoder_activation: 'relu'

  EdgeGraphSAGE:
    hidden_features: 64
    num_layers: 3
    activation: 'relu'
    aggr: 'mean'
    normalize: False
    root_weight: True
    project: False
    bias: True
    encoder_layers: 0
    encoder_activation: 'relu'
    decoder_layers: 3
    decoder_activation: 'relu'

  DUALFloodGNN:
    hidden_features: 64
    num_layers: 3
    activation: 'relu'
    residual: True
    mlp_layers: 3
    encoder_layers: 3
    encoder_activation: 'relu'
    decoder_layers: 3
    decoder_activation: 'relu'

  NodeEdgeGNNAttn:
    hidden_features: 64
    num_layers: 3
    activation: 'relu'
    residual: True
    dropout: 0.0
    negative_slope: 0.2
    attn_mlp_layers: 3
    encoder_layers: 3
    encoder_activation: 'relu'
    decoder_layers: 3
    decoder_activation: 'relu'
  
  NodeGNN:
    hidden_features: 64
    num_layers: 3
    activation: 'relu'
    mlp_layers: 3
    residual: True
    encoder_layers: 3
    encoder_activation: 'relu'
    decoder_layers: 3
    decoder_activation: 'relu'

  EdgeGNN:
    hidden_features: 64
    num_layers: 3
    activation: 'relu'
    mlp_layers: 3
    residual: True
    encoder_layers: 3
    encoder_activation: 'relu'
    decoder_layers: 3
    decoder_activation: 'relu'
